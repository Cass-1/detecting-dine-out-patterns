{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from haversine import haversine_vector\n",
    "import seaborn as sns\n",
    "\n",
    "# Define functions\n",
    "def get_distance_between_rows(df):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance between consecutive rows in a DataFrame (in kilometers)\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing 'latitude' and 'longitude' columns.\n",
    "    Returns:\n",
    "    numpy.ndarray: Array of distances between consecutive rows.\n",
    "    \"\"\"\n",
    "    \n",
    "    coords1 = df[['latitude', 'longitude']].values[:-1]\n",
    "    coords2 = df[['latitude', 'longitude']].values[1:]\n",
    "    distances = haversine_vector(coords1, coords2)\n",
    "    return distances\n",
    "\n",
    "# check\n",
    "def get_time_between_rows(df):\n",
    "    \"\"\"\n",
    "    Calculate the time difference between consecutive rows in a DataFrame (in hours)\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing a 'datetime' column with date and time information.\n",
    "    Returns: numpy.ndarray: Array of time differences between consecutive rows.\n",
    "    \"\"\"\n",
    "\n",
    "    date = pd.to_datetime(df['datetime'])\n",
    "    datetime1 = date.values[:-1]\n",
    "    datetime2 = date.values[1:]\n",
    "    difference = (datetime2 - datetime1).astype('timedelta64[s]')\n",
    "    getHours = np.vectorize(lambda x: x / np.timedelta64(1, 'h'))\n",
    "    return getHours(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = '../../data/movements.csv'\n",
    "movements_data = pd.read_csv(file_path, parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distance and time between each measurement\n",
    "grouped = movements_data.groupby('id')\n",
    "distance_dict = {}\n",
    "time_dict = {}\n",
    "\n",
    "for name, group in grouped:\n",
    "    distances = get_distance_between_rows(group)\n",
    "    times = get_time_between_rows(group)\n",
    "    distance_dict[name] = distances\n",
    "    time_dict[name] = times\n",
    "\n",
    "# replaces missing items w/ NaN\n",
    "distance_results = pd.DataFrame({ key:pd.Series(value) for key, value in distance_dict.items() })\n",
    "time_results = pd.DataFrame({ key:pd.Series(value) for key, value in time_dict.items() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get velocity\n",
    "velocity_results = distance_results / time_results\n",
    "velocity_results.columns = [f'Velocity_{col}' for col in velocity_results.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_movement_data = pd.DataFrame()\n",
    "missing_movement_data['latitude'] = grouped['latitude'].apply(lambda x: x.isna().sum())\n",
    "missing_movement_data['longitude'] = grouped['latitude'].apply(lambda x: x.isna().sum())\n",
    "\n",
    "missing_movement_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify all missing values are due to lengths\n",
    "length = distance_results.notna().sum().reset_index()\n",
    "length.columns = ['id', 'length']\n",
    "length['distance_from_max'] = length['length'] - length['length'].max()\n",
    "\n",
    "length['distance_results_na'] = distance_results.isna().sum().values\n",
    "length['time_results_na'] = time_results.isna().sum().values\n",
    "\n",
    "length.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance_results.apply(lambda x: x.isna().sum()))\n",
    "print(time_results.apply(lambda x: x.isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_results.apply(lambda x: x.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_results.apply(lambda x: x.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Velocity Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1 = 1\n",
    "n_2 = 1\n",
    "# Plot the velocity results for each id in separate graphs with downsampling and rolling averages\n",
    "for col in velocity_results.columns:\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    \n",
    "    # first 10,000 points\n",
    "    downsampled_data = velocity_results[col].iloc[:10000:]\n",
    "    \n",
    "    # Calculate rolling average with a window of 1000 points\n",
    "    # rolling_avg = velocity_results[col].rolling(window=n_2).mean()\n",
    "    \n",
    "    plt.plot(downsampled_data.index, downsampled_data, linestyle='-', label=f'{col}')\n",
    "    # plt.plot(rolling_avg.index, rolling_avg, linestyle='-', color='red', label=f'{col} (Rolling Avg)')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Velocity (km/hr)')\n",
    "    plt.title(f'Velocity Over Time for {col}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Movement Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in distance_results.columns:\n",
    "    # Plot the histogram with logarithmic scaling\n",
    "    sns.histplot(distance_results[col], bins=100, log_scale=(True, False))\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(f'Distance Traveled by {col}(km)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of Distances for {col}')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in distance_results.columns:\n",
    "    # Plot the histogram with logarithmic scaling\n",
    "    sns.histplot([distance for distance in distance_results[col] if distance > 10], bins=100, log_scale=(True, False))\n",
    "    \n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(f'Distance Traveled by {col} > 10(km)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of Distances for {col}')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in distance_results.columns:\n",
    "    # Plot the histogram with logarithmic scaling\n",
    "    sns.histplot([distance for distance in distance_results[col] if distance < 3], bins=100, log_scale=(True, False))\n",
    "    \n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(f'Distance Traveled by {col} > 10(km)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of Distances for {col}')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Velocity Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in velocity_results.columns:\n",
    "    # Plot the histogram with logarithmic scaling\n",
    "    sns.histplot(velocity_results[col], bins=100, log_scale=(True, False))\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(f'Distance Traveled by {col}(km)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of Distances for {col}')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
