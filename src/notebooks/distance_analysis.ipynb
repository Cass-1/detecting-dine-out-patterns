{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from haversine import haversine_vector\n",
    "import seaborn as sns\n",
    "\n",
    "# Define functions\n",
    "def get_distance_between_rows(df):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance between consecutive rows in a DataFrame (in kilometers)\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing 'latitude' and 'longitude' columns.\n",
    "    Returns:\n",
    "    numpy.ndarray: Array of distances between consecutive rows.\n",
    "    \"\"\"\n",
    "    \n",
    "    coords1 = df[['latitude', 'longitude']].values[:-1]\n",
    "    coords2 = df[['latitude', 'longitude']].values[1:]\n",
    "    distances = haversine_vector(coords1, coords2)\n",
    "    return distances\n",
    "\n",
    "# check\n",
    "def get_time_between_rows(df):\n",
    "    \"\"\"\n",
    "    Calculate the time difference between consecutive rows in a DataFrame (in hours)\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing a 'datetime' column with date and time information.\n",
    "    Returns: numpy.ndarray: Array of time differences between consecutive rows.\n",
    "    \"\"\"\n",
    "\n",
    "    date = pd.to_datetime(df['datetime'])\n",
    "    datetime1 = date.values[:-1]\n",
    "    datetime2 = date.values[1:]\n",
    "    difference = (datetime2 - datetime1).astype('timedelta64[s]')\n",
    "    getHours = np.vectorize(lambda x: x / np.timedelta64(1, 'h'))\n",
    "    return getHours(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = '../../data/movements.csv'\n",
    "movements_data = pd.read_csv(file_path, parse_dates=['datetime'])\n",
    "restaurant_data = pd.read_csv(\"../../data/restaurants.csv\")  # Replace with your file path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distance and time between each measurement\n",
    "grouped = movements_data.groupby('id')\n",
    "distance_dict = {}\n",
    "time_dict = {}\n",
    "\n",
    "for name, group in grouped:\n",
    "    distances = get_distance_between_rows(group)\n",
    "    times = get_time_between_rows(group)\n",
    "    distance_dict[name] = distances\n",
    "    time_dict[name] = times\n",
    "\n",
    "# replaces missing items w/ NaN\n",
    "distance_results = pd.DataFrame({ key:pd.Series(value) for key, value in distance_dict.items() })\n",
    "time_results = pd.DataFrame({ key:pd.Series(value) for key, value in time_dict.items() })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get velocity\n",
    "velocity_results = distance_results / time_results\n",
    "velocity_results.columns = [f'Velocity_{col}' for col in velocity_results.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Low Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get low movement\n",
    "LOW_MOVEMENT_BOUND = 0.007826 # determined by 25% of data in distance_results\n",
    "low_movement = pd.DataFrame()\n",
    "for col in distance_results.columns:\n",
    "    low_movement[col] = pd.Series([distance for distance in distance_results[col] if distance < LOW_MOVEMENT_BOUND])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_movement_data = pd.DataFrame()\n",
    "missing_movement_data['latitude'] = grouped['latitude'].apply(lambda x: x.isna().sum())\n",
    "missing_movement_data['longitude'] = grouped['latitude'].apply(lambda x: x.isna().sum())\n",
    "\n",
    "missing_movement_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify all missing values are due to lengths\n",
    "length = distance_results.notna().sum().reset_index()\n",
    "length.columns = ['id', 'length']\n",
    "length['distance_from_max'] = length['length'] - length['length'].max()\n",
    "\n",
    "length['distance_results_na'] = distance_results.isna().sum().values\n",
    "length['time_results_na'] = time_results.isna().sum().values\n",
    "\n",
    "length.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance_results.apply(lambda x: x.isna().sum()))\n",
    "print(time_results.apply(lambda x: x.isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_results.apply(lambda x: x.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_results.apply(lambda x: x.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_movement_in_meters = low_movement * 1000\n",
    "low_movement_in_meters.apply(lambda x: x.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_stretch_no_movement(df, threshold, movements_data):\n",
    "    \"\"\"input in seconds and km\"\"\"\n",
    "    longest_stretch = {}\n",
    "    stretch_timestamps = {}\n",
    "    stretch_durations = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        small_movement = df[col] < threshold\n",
    "        max_stretch = 0\n",
    "        current_stretch = 0\n",
    "        start_index = 0\n",
    "        end_index = 0\n",
    "        \n",
    "        for i, movement in enumerate(small_movement):\n",
    "            if movement:\n",
    "                if current_stretch == 0:\n",
    "                    current_start_index = i\n",
    "                current_stretch += 1\n",
    "            else:\n",
    "                if current_stretch > max_stretch:\n",
    "                    max_stretch = current_stretch\n",
    "                    start_index = current_start_index\n",
    "                    end_index = i - 1\n",
    "                current_stretch = 0\n",
    "        \n",
    "        # Check the last stretch\n",
    "        if current_stretch > max_stretch:\n",
    "            max_stretch = current_stretch\n",
    "            start_index = current_start_index\n",
    "            end_index = len(small_movement) - 1\n",
    "        \n",
    "        longest_stretch[col] = max_stretch\n",
    "        start_time = movements_data.iloc[start_index]['datetime']\n",
    "        end_time = movements_data.iloc[end_index]['datetime']\n",
    "        stretch_timestamps[col] = (start_time, end_time)\n",
    "        stretch_durations[col] = (end_time - start_time).total_seconds() / 3600  # duration in hours\n",
    "    \n",
    "    return longest_stretch, stretch_timestamps, stretch_durations\n",
    "\n",
    "SLEEP_UPPER_BOUND = 0.5 / 1000\n",
    "# Find the longest stretch of no movement for each individual, their timestamps, and durations\n",
    "longest_stretch_no_movement_results, stretch_timestamps, stretch_durations = longest_stretch_no_movement(distance_results, LOW_MOVEMENT_BOUND, movements_data)\n",
    "\n",
    "# Turn the results into a DataFrame\n",
    "longest_stretch_df = pd.DataFrame({\n",
    "    'Longest Stretch (no movement)': longest_stretch_no_movement_results,\n",
    "    'Start Time': {k: v[0] for k, v in stretch_timestamps.items()},\n",
    "    'End Time': {k: v[1] for k, v in stretch_timestamps.items()},\n",
    "    'Duration (hours)': stretch_durations\n",
    "})\n",
    "\n",
    "longest_stretch_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Velocity Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_1 = 1\n",
    "n_2 = 1\n",
    "# Plot the velocity results for each id in separate graphs with downsampling and rolling averages\n",
    "for col in velocity_results.columns:\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    \n",
    "    # first 10,000 points\n",
    "    downsampled_data = velocity_results[col].iloc[:10000:]\n",
    "    \n",
    "    # Calculate rolling average with a window of 1000 points\n",
    "    # rolling_avg = velocity_results[col].rolling(window=n_2).mean()\n",
    "    \n",
    "    plt.plot(downsampled_data.index, downsampled_data, linestyle='-', label=f'{col}')\n",
    "    # plt.plot(rolling_avg.index, rolling_avg, linestyle='-', color='red', label=f'{col} (Rolling Avg)')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Velocity (km/hr)')\n",
    "    plt.title(f'Velocity Over Time for {col}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Movement Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in distance_results.columns:\n",
    "    # Plot the histogram with logarithmic scaling\n",
    "    sns.histplot(distance_results[col], bins=100, log_scale=(True, False))\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(f'Distance Traveled by {col}(km)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of Distances for {col}')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in distance_results.columns:\n",
    "    # Plot the histogram with logarithmic scaling\n",
    "    sns.histplot([distance for distance in distance_results[col] if distance > 10], bins=100, log_scale=(True, False))\n",
    "    \n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(f'Distance Traveled by {col} > 10(km)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of Distances for {col}')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in distance_results.columns:\n",
    "    # Plot the histogram with logarithmic scaling\n",
    "    sns.histplot([distance for distance in distance_results[col] if distance < 3], bins=100, log_scale=(True, False))\n",
    "    \n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(f'Distance Traveled by {col} > 10(km)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of Distances for {col}')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Velocity Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in velocity_results.columns:\n",
    "    # Plot the histogram with logarithmic scaling\n",
    "    sns.histplot(velocity_results[col], bins=100, log_scale=(True, False))\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(f'Distance Traveled by {col}(km)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of Distances for {col}')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Low Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in low_movement.columns:\n",
    "    # Plot the histogram with logarithmic scaling\n",
    "    sns.histplot([distance for distance in low_movement[col]], bins=100)\n",
    "    \n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel(f'Distance Traveled by {col} < ${LOW_MOVEMENT_BOUND}(m)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of Distances for {col}')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Walking Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the restaurant locations\n",
    "plt.scatter(restaurant_data['Longitude'], restaurant_data['Latitude'], label='Restaurants', color='red', marker='s', s=100, alpha=0.7)\n",
    "\n",
    "# Annotate each restaurant with its name\n",
    "for i, row in restaurant_data.iterrows():\n",
    "    plt.annotate(row['Name'], (row['Longitude'], row['Latitude']), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Restaurant Locations')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Restaurants with People's Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the restaurant locations\n",
    "grouped_movements_data = movements_data.groupby('id')\n",
    "for name, group in grouped_movements_data:\n",
    "    plt.scatter(restaurant_data['Longitude'], restaurant_data['Latitude'], label='Restaurants', color='red', marker='s', s=100, alpha=0.7)\n",
    "    # Plot the person's path\n",
    "    person_id = name  # Change this to the desired person's ID\n",
    "    person_data = movements_data[movements_data['id'] == person_id]\n",
    "    plt.plot(person_data['longitude'], person_data['latitude'], label=f'Path of {person_id}', color='blue', alpha=0.6)\n",
    "\n",
    "    # Add title and labels\n",
    "    plt.title(f'Restaurant Locations and {name}\\'s Path')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
